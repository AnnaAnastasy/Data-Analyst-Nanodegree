{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangle Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report briefly describes my wrangling efforts while doing the project (saved as 'wrangle_act.ipynb').\n",
    "\n",
    "Data Wrangling consists of:\n",
    "- data gathering\n",
    "- data assessing\n",
    "- data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I gathered data from 3 different sources:\n",
    "- 'twitter-archive-enhanced.csv', which contains the WeRateDogs Twitter archive, was manually downloaded from Udacity server and read in a dataframe.\n",
    "- Image predictions file was downloaded programmatically using the Requests library and URL 'https://d17h27t6h515a5.cloudfront.net/topher/2017/August/599fd2ad_image-predictions/image-predictions.tsv' and saved into second dataframe.\n",
    "- Additional data (favorite and retweet count) was downloaded by quering the Twitter API using Python's Tweepy library. Then it was imported from Twitter Query as json file and saved into a new dataframe with 3 columns (id, favorite_count, retweet_count), each tweet stored in a line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Assessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I assessed each dataframe first manually, then programatically, using different methods and functions:\n",
    "- **.info()** method to assess null values and datatypes of columns\n",
    "- **selecting data by index** and **by column names** to access part of the data\n",
    "- **df[Series.isnull()]** and **df[Series.notnull()]** to select rows that contain or don't contain null values\n",
    "- **.shape** to see number of rows and columns in the dataframe\n",
    "- **.duplicated()** to check for duplicated rows in the dataframe\n",
    "- **.describe()** to check for suspicious data and outliers\n",
    "- **.value_counts()** to get counts of unique values in the Series\n",
    "- **.head()** to access only first 5 rows of a selected df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After assessing I found following problems:\n",
    "\n",
    "#### Quality Issues\n",
    "- Missing values in some columns (in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id, retweeted_status_timestamp, expanded_urls)\n",
    "- Erroneous datatypes (timestamp, retweeted_status_timestamp)\n",
    "- Unnecessary rows with replies to other people's tweets\n",
    "- 181 rows containing retweets (not original ratings)\n",
    "- Unexpected values in rating numerators and deminators\n",
    "- Tweet with ID `835152434251116546` rated 0/10 for plagiarism\n",
    "- Missing data (as None) in most rows of dog stages and dog names\n",
    "- Erroneous dog names (a, an, the) where a dog name is absent in a tweet\n",
    "- Inconsistency in breed names (some lowercase, some capitalized)\n",
    "\n",
    "#### Tidiness Issue\n",
    "- Rating numerators and denominators should be one variable\n",
    "- Dog stages (doggo, floofer, pupper, puppo) in 4 columns instead of 1\n",
    "- Inconsistency in a column name (tweet ID) among tables\n",
    "- Three dataframes instead of one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After reassessing were detected 2 more issues:\n",
    "\n",
    "#### Quality\n",
    "- Some dogs were not recognized (e.i. index 0: orange, bagel, banana)\n",
    "\n",
    "#### Tidiness\n",
    "- 3 predictions should be narrowed to the most possible one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, I created copies of 3 dataframe.\n",
    "Then I cleaned data in the following sequence:\n",
    "\n",
    "\n",
    "1. Missing data\n",
    "    - Not-null rows in 'in_reply_to_status_id', 'in_reply_to_user_id', 'retweeted_status_id', 'retweeted_status_user_id', 'retweeted_status_timestamp' columns were dropped and then these columns were removed completely\n",
    "    - Null-values in 'expanded_urls' were dropped\n",
    "    - None values in dog stages and names columns were replaced by Nulls\n",
    "    \n",
    "\n",
    "2. Tidiness issues\n",
    "    - 4 columns doggo, floofer, pupper, puppo were turned into one column (Dog stages) using .ffill() method\n",
    "    - Column 'id' was renamed into 'tweet_id' in df3\n",
    "    - All three dataframes were combined into one, using pandas merge function\n",
    "    - Rating numerators and denominators were turned into one rating variable (after performing cleaning of quality issues, i.e fixing numerators and denominators)\n",
    "    \n",
    "    \n",
    "3. Quality issues\n",
    "    - Datatype of 'timestamp' column was converted to datetime\n",
    "    - Observation with id '835152434251116546' was dropped\n",
    "    - All  erroneous dog names were found and replaced with NaN\n",
    "    - All dog breed were converted lowercase\n",
    "    - All suspicious rating numerators and denominators were replaced by correct ones when it was possible\n",
    "    \n",
    "    \n",
    "4. After that, I assessed dataframe again and cleaned 1 remaining quality and 1 tidiness issue:\n",
    "    - Rows that had three Falses in columns 'p1_dog', 'p2_dog', 'p3_dog' were removed, as the dog breed was not detected\n",
    "    - 3 predictions of dog breed were narrowed to the most possible one\n",
    "    \n",
    "All coding was followed by testing to make sure that the code was correct.\n",
    "\n",
    "And I stored final cleaned dataset into 'twitter_archive_master.csv'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "language": "python",
   "name": "python37664bit767a9d6a514e4eb9ac8b22e919039c3d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
